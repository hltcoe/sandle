openapi: 3.0.0
info:
  description: >
    OpenAI-like API implemented by SANDLE, a large language modeling SANDbox for your Local Environment.
  license:
    name: BSD 2-Clause with views sentence
    url: https://spdx.org/licenses/BSD-2-Clause-Views.html
  version: 0.0.1
  title: Sandle API
  contact:
    name: HLTCOE
security:
  - basic: []
  - bearer: []
paths:
  /v1/models:
    get:
      summary: Get a list of models available
      operationId: getModels
      responses:
        '200':
          description: Successful operation
          content:
            application/json:
              schema:
                type: object
                properties:
                  object:
                    type: string
                    enum:
                      - list
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/Model'
        '401':
          description: Invalid authorization
  /v1/models/{model}:
    get:
      summary: Get model info by ID
      operationId: getModel
      parameters:
        - name: model
          in: path
          description: Model ID to look up
          required: true
          style: simple
          schema:
            type: string
            example: facebook/opt-125m
      responses:
        '200':
          description: Successful operation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
        '404':
          description: Model does not exist
        '401':
          description: Invalid authorization
  /v1/completions:
    post:
      summary: Generate text completions
      operationId: completions
      requestBody:
        description: Text to complete and parameters
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Prompt'
      responses:
        '200':
          description: Successful operation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Completion'
            text/event-stream:
              schema:
                type: string
                description: >-
                  A stream of server-sent events representing chunks (subsegments) of the text completion.  Each event is a message with the `data` field populated.  Each chunk is encoded by a message whose `data` field value is a JSON-encoded Completion object.  In contrast to the non-streaming behavior, the `text` field of the `choices` list will contain a chunk of the newly generated text and will not contain the prompt.  The stream will end with a message with `data` field value of `[DONE]`.
                example: |+
                  data: {"id": "4f7e9dd3-c1b2-40bb-be72-24a5487c6beb", "object": "text_completion", "created": 1657745918, "model": "facebook/opt-125m", "choices": [{"text": " I have an egg", "index": 0, "logprobs": null, "finish_reason": null}], "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}}

                  data: {"id": "4f7e9dd3-c1b2-40bb-be72-24a5487c6beb", "object": "text_completion", "created": 1657745918, "model": "facebook/opt-125m", "choices": [{"text": " that matches your TS", "index": 0, "logprobs": null, "finish_reason": null}], "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}}
                  
                  data: {"id": "4f7e9dd3-c1b2-40bb-be72-24a5487c6beb", "object": "text_completion", "created": 1657745918, "model": "facebook/opt-125m", "choices": [{"text": "V. Would you", "index": 0, "logprobs": null, "finish_reason": null}], "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}}
                  
                  data: {"id": "4f7e9dd3-c1b2-40bb-be72-24a5487c6beb", "object": "text_completion", "created": 1657745918, "model": "facebook/opt-125m", "choices": [{"text": " mind hatching it", "index": 0, "logprobs": null, "finish_reason": "length"}], "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}}
                  
                  data: [DONE]

        '400':
          description: Invalid request specification
        '401':
          description: Invalid authorization
        '404':
          description: Model does not exist
components:
  schemas:
    Model:
      type: object
      properties:
        id:
          type: string
          example: facebook/opt-125m
        object:
          type: string
          enum:
            - model
        owned_by:
          type: string
          example: facebook
        permissions:
          type: array
          items:
            type: string
      example: >-
        {"id":"facebook/opt-125m","object":"model","owned_by":"facebook","permission":[]}
    Prompt:
      type: object
      properties:
        model:
          description: ID of model to use
          type: string
        prompt:
          description: >-
            Prompt to complete
          type: string
          default: </s>
        max_tokens:
          description: Maximum number of tokens to generate per completion
          type: integer
          minimum: 1
          default: 16
        temperature:
          description: >-
            Sampling temperature.  Set to 1 to disable;
            see https://huggingface.co/blog/how-to-generate#top-p-nucleus-sampling
            for more information
          type: number
          minimum: 0
          exclusiveMinimum: true
          maximum: 1
          default: 1
        top_p:
          description: >-
            Nucleus sampling probability mass.  Set to 0 or 1 to disable;
            see https://huggingface.co/blog/how-to-generate#top-p-nucleus-sampling
            for more information
          type: number
          minimum: 0
          maximum: 1
          default: 1
        n:
          description: Number of completions to generate per prompt
          type: integer
          minimum: 1
          default: 1
        stream:
          description: >-
            Whether to stream completed text as it is
            produced, via server-side events, or wait
            and return it all at once
          type: boolean
          default: false
        stop:
          description: Sequence or sequences that will end generation early
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          nullable: true
          default: null
        user:
          description: An identifier for the user of the API, for debugging purposes
          type: string
          nullable: true
          default: null
        greedy_decoding:
          description: >-
            Whether to use greedy decoding or sampling for generation.
            This option is an extension of the OpenAI API.
          type: boolean
          default: false
        stream_batch_size:
          description: >-
            Maximum number of completion tokens to generate per batch
            (per message) when `stream` is true.
            If zero, generate the entire completion in one batch.
            This option is an extension of the OpenAI API.
          type: integer
          minimum: 0
          default: 0
      example: >-
        {"model": "facebook/opt-125m", "prompt": "Hello,"}
    Completion:
      type: object
      properties:
        id:
          description: Identifier assigned to this text completion
          type: string
        object:
          description: Type of object
          type: string
          enum: [text_completion]
        created:
          description: Timestamp when text completion was created
          type: integer
          minimum: 0
        model:
          description: Identifier of model used to generate completion
          type: string
        choices:
          description: Text completions generated
          type: array
          items:
            type: object
            properties:
              text:
                description: Text generated to complete prompt
                type: string
              index:
                type: integer
                minimum: 0
              logprobs:
                type: object
                nullable: true
              finish_reason:
                description: Short text code indicating why generation was stopped
                type: string
                enum: [stop, length]
              usage:
                description: Resources used for this request (not currently used)
                type: object
                properties:
                  prompt_tokens:
                    type: integer
                    minimum: 0
                  completion_tokens:
                    type: integer
                    minimum: 0
                  total_tokens:
                    type: integer
                    minimum: 0
      example: >-
        {"choices":[{"finish_reason":"length","index":0,"logprobs":null,"text":"Hello, I have an egg that matches your TSV. Would you mind hatching it"}],"created":1657745801,"id":"a6ad78e8-dac1-419b-80ee-7e4411710a81","model":"facebook/opt-125m","object":"text_completion","usage":{"completion_tokens":0,"prompt_tokens":0,"total_tokens":0}}
  securitySchemes:
    basic:
      type: http
      scheme: basic
    bearer:
      type: http
      scheme: bearer
externalDocs:
  description: Sandle repository on GitHub
  url: http://github.com/hltcoe/sandle
