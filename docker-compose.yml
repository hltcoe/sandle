version: '3'

services:
  demo:
    build:
      context: demo
      args:
        - VITE_SENTRY_DSN=${SENTRY_DSN}
        - VITE_SENTRY_RELEASE=${APP_NAME}@${APP_VERSION}
        # sentry environment is computed automatically
    ports:
      - "${SANDLE_DEMO_PORT:-80}:80"
    depends_on:
      - openai-wrapper
    restart: unless-stopped

  openai-wrapper:
    build:
      context: openai-wrapper
      args:
        - SENTRY_DSN
        - SENTRY_RELEASE=${APP_NAME}@${APP_VERSION}
    command:
      - http://backend-hf:8000/v1/completions
      - --port
      - '8000'
    depends_on:
      - backend-hf
    environment:
      - SANDLE_AUTH_TOKEN
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-development}
    restart: unless-stopped

  backend-hf:
    build:
      context: backend-hf
      args:
        - SENTRY_DSN
        - SENTRY_RELEASE=${APP_NAME}@${APP_VERSION}
    command:
      - --port
      - '8000'
      - --num-gpus
      - '8'
      - --first-gpu-memory
      - '12GB'
      - --successive-gpu-memory
      - '24GB'
    environment:
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-development}
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - huggingface-models:/root/.cache/huggingface

volumes:
  huggingface-models:
