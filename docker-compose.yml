version: '3'

services:
  demo:
    build:
      context: demo
      args:
        - VITE_SENTRY_DSN=${SENTRY_DSN}
        - VITE_SENTRY_RELEASE=${APP_NAME}@${APP_VERSION}
        # sentry environment is computed automatically
    ports:
      - "${SANDLE_DEMO_PORT:-80}:80"
    depends_on:
      - openai-wrapper
    restart: unless-stopped

  openai-wrapper:
    build:
      context: openai-wrapper
      args:
        - SENTRY_DSN
        - SENTRY_RELEASE=${APP_NAME}@${APP_VERSION}
    command:
      - http://backend-hf:8000/v1/completions
      - --port
      - '8000'
      - -l
      - DEBUG
    ## Specify API keys in authorized-users.txt file: part 1/2
    #  - --auth-token-is-user
    #  - --auth-token-file
    #  - /opt/sandle/authorized-users.txt
    depends_on:
      - backend-hf
    environment:
      - SANDLE_AUTH_TOKEN
      - SANDLE_SINGLE_MODEL
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-development}
    restart: unless-stopped
    ## Specify API keys in authorized-users.txt file: part 2/2
    #volumes:
    #  - type: bind
    #    source: ./authorized-users.txt
    #    target: /opt/sandle/authorized-users.txt
    #    read_only: true

  backend-hf:
    build:
      context: backend-hf
      args:
        - SENTRY_DSN
        - SENTRY_RELEASE=${APP_NAME}@${APP_VERSION}
    command:
      - --port
      - '8000'
    environment:
      - SANDLE_SINGLE_MODEL
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-development}
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - huggingface-models:/root/.cache/huggingface

volumes:
  huggingface-models:
